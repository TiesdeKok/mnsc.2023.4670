{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preamble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "NAME = 'a_6c_calculate_text_metrics' \n",
    "PROJECT = 'covid-empirical'\n",
    "PYTHON_VERSION = '3.9'\n",
    "USER = 'linuxBox' ## Note, this notebook is designed to run on Linux.\n",
    "CONDA_ENVIRONMENT = 'covid-empirical'\n",
    "USE_EXTERNAL_PIPELINE = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run preamble script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------\n",
      "The following utility functions are loaded and available through `functions.<..>`:\n",
      "----------------------------------------------------------------------------------\n",
      "\n",
      "extract_data_edgar_link, fast_load_json, fast_store_json, flatten_multiindex_column, inDB, recreate_edgar_link\n",
      "\n",
      "----------------------------------------------------------------\n",
      "The following modules and functions are imported by preamble.py:\n",
      "----------------------------------------------------------------\n",
      "\n",
      "copy, delayed, importlib, json, math, np, orjson, os, pd, plt, pqdm_p, pqdm_t, random, re, requests, sys, time, yaml\n"
     ]
    }
   ],
   "source": [
    "%run -i preamble.py "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook specific imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import html\n",
    "import unidecode\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Syllables parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyphen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "syllable_parser = pyphen.Pyphen(lang = 'en_US')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm', disable = ['tok2vec', 'tagger' ,'parser' ,'attribute_ruler', 'lemmatizer', 'ner'])\n",
    "nlp.enable_pipe('senter')\n",
    "nlp.max_length = 3_000_000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------\n",
    "# Load processed filings\n",
    "---------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "filing_df = pd.read_hdf(Path.cwd() / '2_pipeline' / 'a_6a_download_raw_filings' / 'out' / 'filing_df.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Index done files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_done_folder = externalPipelineFolder / 'a_6b_parse_filings' / 'out' / 'full'\n",
    "split_done_folder = externalPipelineFolder / 'a_6b_parse_filings' / 'out' / 'split'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of filing done in the full dataset: 81,109\n"
     ]
    }
   ],
   "source": [
    "full_done_dict = {}\n",
    "full_done_list = []\n",
    "for folder in os.listdir(full_done_folder):\n",
    "    full_done_dict[folder] = []\n",
    "    for file in (full_done_folder / folder).glob('*.json.gz'):\n",
    "        full_done_dict[file.name] = file\n",
    "        full_done_list.append(file)\n",
    "        \n",
    "print(f'Number of filing done in the full dataset: {len(full_done_list):,}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of filing done in the split dataset: 72,996\n"
     ]
    }
   ],
   "source": [
    "split_done_dict = {}\n",
    "split_done_list = []\n",
    "for folder in os.listdir(split_done_folder):\n",
    "    split_done_dict[folder] = []\n",
    "    for file in (split_done_folder / folder).glob('*.json.gz'):\n",
    "        split_done_dict[file.name] = file\n",
    "        split_done_list.append(file)\n",
    "\n",
    "print(f'Number of filing done in the split dataset: {len(split_done_list):,}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.sec.gov/Archives/edgar/data/1750/000110465921118843/air-20210831x10q.htm\n",
      "https://www.sec.gov/Archives/edgar/data/1750/000110465921118843/air-20210831x10q.htm\n"
     ]
    }
   ],
   "source": [
    "index_to_load = 17\n",
    "full_data = functions.fast_load_json(full_done_list[index_to_load])\n",
    "print(full_data['link'])\n",
    "full_text = full_data['filing_text']\n",
    "split_data = functions.fast_load_json(split_done_list[index_to_load])\n",
    "split_text_list = split_data['filing_list']\n",
    "print(split_data['link'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------------\n",
    "# Text metric logic\n",
    "------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Development params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = full_text\n",
    "filing_details = functions.extract_data_edgar_link(full_data['link'])\n",
    "verbose = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Covid keywords\n",
    "\n",
    "https://www.nature.com/articles/s41599-022-01039-1\n",
    "\n",
    ">  Since this study examines the attention attributed to COVID-19 in the SEC filings, the discovery mechanism of relevant COVID-19 mentions is of central importance. To mitigate susceptibility to errors due to word splitting, stemming and other text preprocessing, we decided for the most simple approach based on the matching of regular expressions. We scanned the reports for the **two relatively unambiguous terms ‘corona’ and ‘covid’**, also accounting for ‘coronavirus’ and ‘covid-19’ without duplication. For this process, the entire text is set to lower case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_covid_words(text:str)->dict:\n",
    "    covid_keywords = ['corona', 'covid'] \n",
    "\n",
    "    text_lower = text.lower() \n",
    "\n",
    "    covid_count_dict = {}\n",
    "    for kw in covid_keywords:\n",
    "        count = text_lower.count(kw)\n",
    "        covid_count_dict[kw] = count\n",
    "\n",
    "    return covid_count_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'corona': 1, 'covid': 7}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_covid_words(full_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Syllables logic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_syllables(word, syllable_parser=syllable_parser):\n",
    "    if not isinstance(word, str):\n",
    "        word = str(word)\n",
    "    syllables = syllable_parser.inserted(word.lower()).split(\"-\")\n",
    "    return syllables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "word = nlp('University')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['uni', 'ver', 'si', 'ty']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_syllables(word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Complexity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check validity of sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_validity_sentence(sen):\n",
    "    sen_str = str(sen)\n",
    "    token_list  = [token for token in sen if not token.is_punct]\n",
    "    all_chars = ''.join([str(token) for token in token_list])\n",
    "\n",
    "    valid_sen = True\n",
    "\n",
    "    ## If too many uppercase characters, not a valid sentence. \n",
    "    num_char = len(all_chars)\n",
    "    num_upper = len([x for x in all_chars if x.isupper()])\n",
    "    \n",
    "    if not num_char:\n",
    "        valid_sen = False\n",
    "\n",
    "    if valid_sen:\n",
    "        perc_upper = num_upper / num_char \n",
    "        if perc_upper > 0.33:\n",
    "            valid_sen = False\n",
    "\n",
    "    ## Require a sentence to have at least 10 characters\n",
    "    if valid_sen:\n",
    "        if num_char < 10:\n",
    "            valid_sen = False\n",
    "        \n",
    "    ## If starts with Yes --> false\n",
    "    if valid_sen:\n",
    "        if sen_str[:3] == 'Yes':\n",
    "            valid_sen = False\n",
    "        \n",
    "    ## Check for valid sentence endings\n",
    "    valid_text_endings = ['.', '?', '!', \"'\", '\"', \":\"]\n",
    "    if valid_sen:\n",
    "        if sen_str[-1] not in valid_text_endings:\n",
    "            valid_sen = False\n",
    "            \n",
    "    ## Check for sentence start\n",
    "    if valid_sen:\n",
    "        if sen_str[0] in ['<', '(', '[', '{']:\n",
    "            valid_sen = False\n",
    "            \n",
    "    ## Check for count of special characters\n",
    "    for special_char in ['*', ':', ';', '-', '_']:\n",
    "        if valid_sen:\n",
    "            if sen_str.count(special_char) > 5:\n",
    "                valid_sen = False\n",
    "                \n",
    "    return valid_sen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions to split into tokens and sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seg_and_token_spacy(document):\n",
    "    processed_doc = nlp(document)\n",
    "    sen_list_raw = list(processed_doc.sents)\n",
    "    sen_list = []\n",
    "    for sen in sen_list_raw:\n",
    "        if check_validity_sentence(sen):\n",
    "            sen_list.append([token for token in sen if not token.is_punct])\n",
    "        \n",
    "    return sen_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate text metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_metrics_for_sentence(sen_comp, debug = False):\n",
    "    sen_dict = {\n",
    "        'number_of_tokens' : len(sen_comp),\n",
    "        'number_of_words' : np.nan,\n",
    "        'number_of_numbers' : 0,\n",
    "        'number_of_complex_words' : 0\n",
    "    }\n",
    "\n",
    "    tokens_word, tokens_number = [], []\n",
    "    for token in sen_comp:\n",
    "        if token.is_alpha:\n",
    "            tokens_word.append(token)\n",
    "        elif token.is_digit:\n",
    "            tokens_number.append(token)\n",
    "            \n",
    "    sen_dict['number_of_words'] = len(tokens_word)\n",
    "    sen_dict['number_of_numbers'] = len(tokens_number)\n",
    "\n",
    "    syl_list = []\n",
    "    for sub_l in [get_syllables(token) for token in tokens_word]:\n",
    "        num_valid_syl = 0\n",
    "        for i, item in enumerate(sub_l):\n",
    "            if len(sub_l) != 3:\n",
    "                num_valid_syl += 1\n",
    "            else:\n",
    "                if item not in ['es', 'ed']:\n",
    "                    num_valid_syl += 1\n",
    "        syl_list.append(num_valid_syl)\n",
    "    \n",
    "    if debug:\n",
    "        for i, token in enumerate(tokens_word):\n",
    "            print(token, syl_list[i])\n",
    "        print()\n",
    "\n",
    "    sen_dict['number_of_complex_words'] = np.count_nonzero([x > 2 for x in syl_list])\n",
    "    \n",
    "    return sen_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_metrics_for_text(text:str, filing_details:dict, include_covid:bool=False)->dict:\n",
    "    full_metric_dict = {\n",
    "        'uniqueID' : filing_details['uniqueID'],\n",
    "        'number_of_sentences' : 0, \n",
    "        'number_of_tokens' : 0,\n",
    "        'number_of_words' : 0,\n",
    "        'number_of_numbers' : 0,\n",
    "        'number_of_complex_words' : 0,\n",
    "        'average_sen_length' : np.nan,\n",
    "        'perc_complex_words' : np.nan,\n",
    "        'fog_index' : np.nan,\n",
    "    }\n",
    "\n",
    "    sentence_components = seg_and_token_spacy(text)\n",
    "    full_metric_dict['number_of_sentences'] = len(sentence_components)\n",
    "\n",
    "    ## Sentence level metrics\n",
    "    metric_list = []\n",
    "    for sen_comp in sentence_components:\n",
    "        metric_list.append(calc_metrics_for_sentence(sen_comp, debug=False))\n",
    "\n",
    "    ## Aggregate to document level\n",
    "\n",
    "    for metric_dict in metric_list:\n",
    "        for k,v in metric_dict.items():\n",
    "            full_metric_dict[k] += v\n",
    "\n",
    "    ## Complexity metrics for FOG\n",
    "    if full_metric_dict['number_of_sentences'] and full_metric_dict['number_of_words']:\n",
    "        full_metric_dict['average_sen_length'] =  full_metric_dict['number_of_words'] / full_metric_dict['number_of_sentences']\n",
    "        full_metric_dict['perc_complex_words'] =  full_metric_dict['number_of_complex_words'] / full_metric_dict['number_of_words']\n",
    "        full_metric_dict['fog_index'] =  0.4 * (full_metric_dict['average_sen_length'] + 100 * full_metric_dict['perc_complex_words'])\n",
    "    \n",
    "    if include_covid:\n",
    "        ## Covid words\n",
    "        covid_dict = count_covid_words(text)\n",
    "        total_covid = sum([v for k,v in covid_dict.items()])\n",
    "        full_metric_dict['number_of_covid_words'] = total_covid \n",
    "\n",
    "    return full_metric_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identify sections for `risk factors` and `mda`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def identify_sections_of_interest(filing_list:list)->dict:\n",
    "    sections = []\n",
    "    for item in filing_list:\n",
    "        if item['section_label'] not in sections:\n",
    "            sections.append(item['section_label'])\n",
    "\n",
    "    #### Identify risk factors\n",
    "\n",
    "    risk_factor_section, mda_section = '', ''\n",
    "    for section in sections:\n",
    "        section_lower = section.lower()\n",
    "        if not risk_factor_section:\n",
    "            if all([term in section_lower for term in ['risk', 'factors']]) and not any([term in section_lower for term in ['quantitative', 'summary']]):\n",
    "                risk_factor_section = section\n",
    "        if not mda_section:\n",
    "            if all([term in section_lower for term in ['management', 'discussion', 'analysis']]):\n",
    "                mda_section = section\n",
    "                \n",
    "    return {\n",
    "        'risk_factor_label' : risk_factor_section,\n",
    "        'mda_label' : mda_section\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Risk factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_metric_risk_factor(filing_list:list, label_dict:dict, filing_details:dict):\n",
    "    full_metric_dict = {\n",
    "        'uniqueID' : filing_details['uniqueID'],\n",
    "        'number_of_sentences' : np.nan, \n",
    "        'number_of_tokens' : np.nan,\n",
    "        'number_of_words' : np.nan,\n",
    "        'number_of_numbers' : np.nan,\n",
    "        'number_of_complex_words' : np.nan,\n",
    "        'average_sen_length' : np.nan,\n",
    "        'perc_complex_words' : np.nan,\n",
    "        'fog_index' : np.nan,\n",
    "        'number_of_covid_words' : np.nan,\n",
    "        'number_of_risk_factors' : np.nan\n",
    "    }\n",
    "\n",
    "    risk_factor_label = label_dict['risk_factor_label']\n",
    "    if risk_factor_label:\n",
    "        rf_items = [item for item in filing_list if item['section_label'] == risk_factor_label]\n",
    "\n",
    "        ## Identify the text and risk factor headers\n",
    "        all_text = ' '.join([item['clean_text'] for item in rf_items])\n",
    "        valid_text = ' '.join([item['clean_text'] for item in rf_items if item['type'] in ['text']])\n",
    "        risk_factor_list = []\n",
    "        for i, item in enumerate(rf_items):\n",
    "            if item['type'] in ['header', 'sub-header']:\n",
    "                header_text = item['clean_text']\n",
    "                header_text_lower  = header_text.lower()\n",
    "                if header_text not in risk_factor_list and not re.search('item \\d', header_text_lower):\n",
    "                    if not all([term in header_text_lower for term in ['risk', 'factors']]):\n",
    "                        if not all([term in header_text_lower for term in ['face', 'materially', 'risks']]):\n",
    "                            if i < (len(rf_items) - 1):\n",
    "                                if rf_items[i+1]['type'] not in ['sub-header', 'header']: ## This prevents group headers from counting as a risk factor\n",
    "                                    risk_factor_list.append(item['clean_text'])\n",
    "                    \n",
    "        ## Calculate metrics\n",
    "        \n",
    "        ### Covid\n",
    "        covid_dict = count_covid_words(all_text)\n",
    "        total_covid = sum([v for k,v in covid_dict.items()])\n",
    "        full_metric_dict['number_of_covid_words'] = total_covid \n",
    "        \n",
    "        ### Risk factors\n",
    "        full_metric_dict['number_of_risk_factors'] = len(risk_factor_list)\n",
    "        \n",
    "        ### Text statistics\n",
    "        for k,v in calc_metrics_for_text(valid_text, filing_details, include_covid=False).items():\n",
    "            if k not in ['uniqueID']:\n",
    "                full_metric_dict[k] = v\n",
    "        \n",
    "    \n",
    "    return full_metric_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MD&A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_metric_mda(filing_list:list, label_dict:dict, filing_details:dict):\n",
    "\n",
    "    full_metric_dict = {\n",
    "            'uniqueID' : filing_details['uniqueID'],\n",
    "            'number_of_sentences' : np.nan, \n",
    "            'number_of_tokens' : np.nan,\n",
    "            'number_of_words' : np.nan,\n",
    "            'number_of_numbers' : np.nan,\n",
    "            'number_of_complex_words' : np.nan,\n",
    "            'average_sen_length' : np.nan,\n",
    "            'perc_complex_words' : np.nan,\n",
    "            'fog_index' : np.nan,\n",
    "            'number_of_covid_words' : np.nan,\n",
    "        }\n",
    "\n",
    "    mda_label = label_dict['mda_label']\n",
    "    if mda_label:\n",
    "        mda_items = [item for item in filing_list if item['section_label'] == mda_label]\n",
    "\n",
    "        ## Identify the text and risk factor headers\n",
    "        all_text = ' '.join([item['clean_text'] for item in mda_items])\n",
    "        valid_text = ' '.join([item['clean_text'] for item in mda_items if item['type'] in ['text']])\n",
    "\n",
    "        ## Calculate metrics\n",
    "\n",
    "        ### Covid\n",
    "        covid_dict = count_covid_words(all_text)\n",
    "        total_covid = sum([v for k,v in covid_dict.items()])\n",
    "        full_metric_dict['number_of_covid_words'] = total_covid \n",
    "\n",
    "        ### Text statistics\n",
    "        for k,v in calc_metrics_for_text(valid_text, filing_details, include_covid=False).items():\n",
    "            if k not in ['uniqueID']:\n",
    "                full_metric_dict[k] = v\n",
    "                \n",
    "    return full_metric_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combo function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_all_for_filing(filename:str, verbose:int=0)->dict:\n",
    "    file_path_full = full_done_dict[filename]\n",
    "    file_path_split, sections_extracted =  None, False\n",
    "    if filename in split_done_dict.keys():\n",
    "        file_path_split = split_done_dict[filename]\n",
    "        sections_extracted = True\n",
    "\n",
    "    ## Load data\n",
    "    full_data = functions.fast_load_json(file_path_full)\n",
    "    if file_path_split:\n",
    "        split_data = functions.fast_load_json(file_path_split)\n",
    "\n",
    "    filing_details = functions.extract_data_edgar_link(full_data['link'])\n",
    "    if verbose > 0:\n",
    "        print(filing_details['link'])\n",
    "\n",
    "    filing_metrics = {}\n",
    "    for key in ['link', 'uniqueID', 'cik', 'cik_padded']:\n",
    "        filing_metrics[key]  = filing_details[key]\n",
    "\n",
    "    filing_metrics['sections_extracted'] = sections_extracted\n",
    "    \n",
    "    ## ---------------------\n",
    "    ## Stats for full filing\n",
    "    ## ---------------------\n",
    "\n",
    "    full_text = full_data['filing_text']\n",
    "    full_metrics = calc_metrics_for_text(full_text,filing_details, include_covid=True)\n",
    "\n",
    "    ## Add to filing level metrics\n",
    "    for k,v in full_metrics.items():\n",
    "        if k not in ['uniqueID']:\n",
    "            filing_metrics['full_'+k]  = v\n",
    "\n",
    "    ## ------------------\n",
    "    ## Stats for sections\n",
    "    ## ------------------\n",
    "    \n",
    "    if file_path_split:\n",
    "        filing_list = split_data['filing_list']\n",
    "\n",
    "        label_dict = identify_sections_of_interest(filing_list)\n",
    "\n",
    "        rf_metrics = calc_metric_risk_factor(filing_list, label_dict, filing_details)\n",
    "        mda_metrics = calc_metric_mda(filing_list, label_dict, filing_details)\n",
    "\n",
    "        ## Add to filing level metrics\n",
    "        for k,v in rf_metrics.items():\n",
    "            if k not in ['uniqueID']:\n",
    "                filing_metrics['rf_'+k]  = v\n",
    "\n",
    "        for k,v in mda_metrics.items():\n",
    "            if k not in ['uniqueID']:\n",
    "                filing_metrics['mda_'+k]  = v\n",
    "    \n",
    "    return filing_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------\n",
    "## Debug and testing\n",
    "---------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "745732-=-000074573217000034-=-rost-20171028x10q-=-htm.json.gz\n",
      "https://www.sec.gov/Archives/edgar/data/745732/000074573217000034/rost-20171028x10q.htm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'link': 'https://www.sec.gov/Archives/edgar/data/745732/000074573217000034/rost-20171028x10q.htm',\n",
       " 'uniqueID': '745732-=-000074573217000034-=-rost-20171028x10q-=-htm',\n",
       " 'cik': '745732',\n",
       " 'cik_padded': '0000745732',\n",
       " 'sections_extracted': False,\n",
       " 'full_number_of_sentences': 357,\n",
       " 'full_number_of_tokens': 9634,\n",
       " 'full_number_of_words': 8810,\n",
       " 'full_number_of_numbers': 562,\n",
       " 'full_number_of_complex_words': 1936,\n",
       " 'full_average_sen_length': 24.677871148459385,\n",
       " 'full_perc_complex_words': 0.21975028376844494,\n",
       " 'full_fog_index': 18.661159810121553,\n",
       " 'full_number_of_covid_words': 0}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename = full_done_list[3201].name\n",
    "print(filename)\n",
    "calc_all_for_filing(filename,verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------------\n",
    "# Run\n",
    "-------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combo_func(file):\n",
    "    with warnings.catch_warnings():\n",
    "        try:\n",
    "            warnings.simplefilter(\"ignore\")\n",
    "            filename  = file.name\n",
    "            return True, calc_all_for_filing(filename,verbose = 0)\n",
    "        except Exception as e:\n",
    "            return False, str(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "todo_files = full_done_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7df93fc9e51149f0a4c844e570c4ca65",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "QUEUEING TASKS | :   0%|          | 0/81109 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "deec325c609c46cb9dc82c0864bb3ffe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "PROCESSING TASKS | :   0%|          | 0/81109 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8dddd81193d44223bc7c11088af162f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "COLLECTING RESULTS | :   0%|          | 0/81109 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "res_list = pqdm_p(todo_files, combo_func, n_jobs = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "81109\n"
     ]
    }
   ],
   "source": [
    "full_metric_list = []\n",
    "fail_list = []\n",
    "for status, res in res_list:\n",
    "    if status:\n",
    "        full_metric_list.append(res)\n",
    "    else:\n",
    "        fail_list.append(res)\n",
    "print(len(full_metric_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_metric_df = pd.DataFrame(full_metric_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add meta data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_metric_df = pd.merge(full_metric_df, filing_df[['uniqueID', 'filingDate', 'reportDate', 'form']], on = 'uniqueID', how = 'left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deal with risk factors in 10-Q\n",
    "\n",
    "Often the company does not include risk factors in the 10-Q, only by reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_list = []\n",
    "for index, row in full_metric_df.iterrows():\n",
    "    if row['rf_number_of_sentences'] <= 5:\n",
    "        for k,v in row.iteritems():\n",
    "            if 'rf_'  == k[:3]:\n",
    "                row[k]  = np.nan\n",
    "    \n",
    "    new_list.append(row.to_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_metric_df = pd.DataFrame(new_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>full_number_of_sentences</th>\n",
       "      <td>20083.0</td>\n",
       "      <td>1776.259374</td>\n",
       "      <td>733.293568</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>1337.000000</td>\n",
       "      <td>1675.000000</td>\n",
       "      <td>2087.000000</td>\n",
       "      <td>11659.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>full_number_of_tokens</th>\n",
       "      <td>20083.0</td>\n",
       "      <td>53824.337549</td>\n",
       "      <td>23530.824854</td>\n",
       "      <td>499.000000</td>\n",
       "      <td>39409.500000</td>\n",
       "      <td>50404.000000</td>\n",
       "      <td>64103.000000</td>\n",
       "      <td>351271.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>full_number_of_words</th>\n",
       "      <td>20083.0</td>\n",
       "      <td>50985.993377</td>\n",
       "      <td>22314.469008</td>\n",
       "      <td>466.000000</td>\n",
       "      <td>37250.000000</td>\n",
       "      <td>47740.000000</td>\n",
       "      <td>60792.500000</td>\n",
       "      <td>325301.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>full_number_of_numbers</th>\n",
       "      <td>20083.0</td>\n",
       "      <td>1501.465269</td>\n",
       "      <td>826.719945</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>1046.000000</td>\n",
       "      <td>1348.000000</td>\n",
       "      <td>1756.500000</td>\n",
       "      <td>16641.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>full_number_of_complex_words</th>\n",
       "      <td>20083.0</td>\n",
       "      <td>11052.724842</td>\n",
       "      <td>5073.199625</td>\n",
       "      <td>136.000000</td>\n",
       "      <td>8015.500000</td>\n",
       "      <td>10298.000000</td>\n",
       "      <td>13091.500000</td>\n",
       "      <td>76774.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>full_average_sen_length</th>\n",
       "      <td>20083.0</td>\n",
       "      <td>28.468860</td>\n",
       "      <td>2.248223</td>\n",
       "      <td>10.355556</td>\n",
       "      <td>26.962952</td>\n",
       "      <td>28.362340</td>\n",
       "      <td>29.893670</td>\n",
       "      <td>40.606082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>full_perc_complex_words</th>\n",
       "      <td>20083.0</td>\n",
       "      <td>0.216518</td>\n",
       "      <td>0.011421</td>\n",
       "      <td>0.170551</td>\n",
       "      <td>0.209099</td>\n",
       "      <td>0.215977</td>\n",
       "      <td>0.223295</td>\n",
       "      <td>0.299351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>full_fog_index</th>\n",
       "      <td>20083.0</td>\n",
       "      <td>20.048261</td>\n",
       "      <td>0.925704</td>\n",
       "      <td>14.009707</td>\n",
       "      <td>19.428891</td>\n",
       "      <td>20.035036</td>\n",
       "      <td>20.638801</td>\n",
       "      <td>24.229627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>full_number_of_covid_words</th>\n",
       "      <td>20083.0</td>\n",
       "      <td>19.674102</td>\n",
       "      <td>29.987178</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>590.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rf_number_of_sentences</th>\n",
       "      <td>17840.0</td>\n",
       "      <td>342.532399</td>\n",
       "      <td>202.532248</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>202.000000</td>\n",
       "      <td>290.000000</td>\n",
       "      <td>437.000000</td>\n",
       "      <td>2053.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rf_number_of_tokens</th>\n",
       "      <td>17840.0</td>\n",
       "      <td>11147.181558</td>\n",
       "      <td>7068.365545</td>\n",
       "      <td>146.000000</td>\n",
       "      <td>6219.750000</td>\n",
       "      <td>9246.500000</td>\n",
       "      <td>14416.250000</td>\n",
       "      <td>61996.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rf_number_of_words</th>\n",
       "      <td>17840.0</td>\n",
       "      <td>10989.334025</td>\n",
       "      <td>6968.095707</td>\n",
       "      <td>146.000000</td>\n",
       "      <td>6122.750000</td>\n",
       "      <td>9116.500000</td>\n",
       "      <td>14232.000000</td>\n",
       "      <td>60754.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rf_number_of_numbers</th>\n",
       "      <td>17840.0</td>\n",
       "      <td>65.817489</td>\n",
       "      <td>65.075752</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>51.000000</td>\n",
       "      <td>88.000000</td>\n",
       "      <td>1737.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rf_number_of_complex_words</th>\n",
       "      <td>17840.0</td>\n",
       "      <td>2352.144787</td>\n",
       "      <td>1477.003933</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>1332.000000</td>\n",
       "      <td>1967.500000</td>\n",
       "      <td>3011.250000</td>\n",
       "      <td>13401.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rf_average_sen_length</th>\n",
       "      <td>17840.0</td>\n",
       "      <td>31.413382</td>\n",
       "      <td>2.714418</td>\n",
       "      <td>18.846154</td>\n",
       "      <td>29.689750</td>\n",
       "      <td>31.392476</td>\n",
       "      <td>33.104336</td>\n",
       "      <td>51.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rf_perc_complex_words</th>\n",
       "      <td>17840.0</td>\n",
       "      <td>0.216014</td>\n",
       "      <td>0.015284</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>0.206099</td>\n",
       "      <td>0.214950</td>\n",
       "      <td>0.223738</td>\n",
       "      <td>0.304878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rf_fog_index</th>\n",
       "      <td>17840.0</td>\n",
       "      <td>21.205914</td>\n",
       "      <td>1.165795</td>\n",
       "      <td>14.722135</td>\n",
       "      <td>20.465911</td>\n",
       "      <td>21.200292</td>\n",
       "      <td>21.911407</td>\n",
       "      <td>30.499240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rf_number_of_covid_words</th>\n",
       "      <td>17840.0</td>\n",
       "      <td>7.321244</td>\n",
       "      <td>11.302619</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>220.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rf_number_of_risk_factors</th>\n",
       "      <td>17840.0</td>\n",
       "      <td>39.825617</td>\n",
       "      <td>20.750268</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>52.000000</td>\n",
       "      <td>369.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mda_number_of_sentences</th>\n",
       "      <td>18188.0</td>\n",
       "      <td>320.240268</td>\n",
       "      <td>231.268920</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>201.000000</td>\n",
       "      <td>282.000000</td>\n",
       "      <td>388.000000</td>\n",
       "      <td>7178.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mda_number_of_tokens</th>\n",
       "      <td>18188.0</td>\n",
       "      <td>9455.689521</td>\n",
       "      <td>6719.782143</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5911.250000</td>\n",
       "      <td>8367.500000</td>\n",
       "      <td>11545.000000</td>\n",
       "      <td>193365.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mda_number_of_words</th>\n",
       "      <td>18188.0</td>\n",
       "      <td>8776.689960</td>\n",
       "      <td>6266.237719</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5498.750000</td>\n",
       "      <td>7783.000000</td>\n",
       "      <td>10705.250000</td>\n",
       "      <td>181664.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mda_number_of_numbers</th>\n",
       "      <td>18188.0</td>\n",
       "      <td>337.337915</td>\n",
       "      <td>273.872302</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>181.000000</td>\n",
       "      <td>280.000000</td>\n",
       "      <td>424.000000</td>\n",
       "      <td>5669.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mda_number_of_complex_words</th>\n",
       "      <td>18188.0</td>\n",
       "      <td>1803.977348</td>\n",
       "      <td>1397.206494</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1105.000000</td>\n",
       "      <td>1572.000000</td>\n",
       "      <td>2181.000000</td>\n",
       "      <td>39937.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mda_average_sen_length</th>\n",
       "      <td>18078.0</td>\n",
       "      <td>27.535121</td>\n",
       "      <td>3.107965</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>25.571429</td>\n",
       "      <td>27.432850</td>\n",
       "      <td>29.342129</td>\n",
       "      <td>73.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mda_perc_complex_words</th>\n",
       "      <td>18078.0</td>\n",
       "      <td>0.205497</td>\n",
       "      <td>0.023842</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.193641</td>\n",
       "      <td>0.203478</td>\n",
       "      <td>0.213732</td>\n",
       "      <td>0.476190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mda_fog_index</th>\n",
       "      <td>18078.0</td>\n",
       "      <td>19.233938</td>\n",
       "      <td>1.509056</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>18.331666</td>\n",
       "      <td>19.161522</td>\n",
       "      <td>20.025399</td>\n",
       "      <td>41.254795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mda_number_of_covid_words</th>\n",
       "      <td>18188.0</td>\n",
       "      <td>6.360512</td>\n",
       "      <td>11.452847</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>114.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                count          mean           std         min  \\\n",
       "full_number_of_sentences      20083.0   1776.259374    733.293568   32.000000   \n",
       "full_number_of_tokens         20083.0  53824.337549  23530.824854  499.000000   \n",
       "full_number_of_words          20083.0  50985.993377  22314.469008  466.000000   \n",
       "full_number_of_numbers        20083.0   1501.465269    826.719945    9.000000   \n",
       "full_number_of_complex_words  20083.0  11052.724842   5073.199625  136.000000   \n",
       "full_average_sen_length       20083.0     28.468860      2.248223   10.355556   \n",
       "full_perc_complex_words       20083.0      0.216518      0.011421    0.170551   \n",
       "full_fog_index                20083.0     20.048261      0.925704   14.009707   \n",
       "full_number_of_covid_words    20083.0     19.674102     29.987178    0.000000   \n",
       "rf_number_of_sentences        17840.0    342.532399    202.532248    6.000000   \n",
       "rf_number_of_tokens           17840.0  11147.181558   7068.365545  146.000000   \n",
       "rf_number_of_words            17840.0  10989.334025   6968.095707  146.000000   \n",
       "rf_number_of_numbers          17840.0     65.817489     65.075752    0.000000   \n",
       "rf_number_of_complex_words    17840.0   2352.144787   1477.003933   37.000000   \n",
       "rf_average_sen_length         17840.0     31.413382      2.714418   18.846154   \n",
       "rf_perc_complex_words         17840.0      0.216014      0.015284    0.150000   \n",
       "rf_fog_index                  17840.0     21.205914      1.165795   14.722135   \n",
       "rf_number_of_covid_words      17840.0      7.321244     11.302619    0.000000   \n",
       "rf_number_of_risk_factors     17840.0     39.825617     20.750268    0.000000   \n",
       "mda_number_of_sentences       18188.0    320.240268    231.268920    0.000000   \n",
       "mda_number_of_tokens          18188.0   9455.689521   6719.782143    0.000000   \n",
       "mda_number_of_words           18188.0   8776.689960   6266.237719    0.000000   \n",
       "mda_number_of_numbers         18188.0    337.337915    273.872302    0.000000   \n",
       "mda_number_of_complex_words   18188.0   1803.977348   1397.206494    0.000000   \n",
       "mda_average_sen_length        18078.0     27.535121      3.107965    7.000000   \n",
       "mda_perc_complex_words        18078.0      0.205497      0.023842    0.000000   \n",
       "mda_fog_index                 18078.0     19.233938      1.509056    4.000000   \n",
       "mda_number_of_covid_words     18188.0      6.360512     11.452847    0.000000   \n",
       "\n",
       "                                       25%           50%           75%  \\\n",
       "full_number_of_sentences       1337.000000   1675.000000   2087.000000   \n",
       "full_number_of_tokens         39409.500000  50404.000000  64103.000000   \n",
       "full_number_of_words          37250.000000  47740.000000  60792.500000   \n",
       "full_number_of_numbers         1046.000000   1348.000000   1756.500000   \n",
       "full_number_of_complex_words   8015.500000  10298.000000  13091.500000   \n",
       "full_average_sen_length          26.962952     28.362340     29.893670   \n",
       "full_perc_complex_words           0.209099      0.215977      0.223295   \n",
       "full_fog_index                   19.428891     20.035036     20.638801   \n",
       "full_number_of_covid_words        0.000000      1.000000     34.000000   \n",
       "rf_number_of_sentences          202.000000    290.000000    437.000000   \n",
       "rf_number_of_tokens            6219.750000   9246.500000  14416.250000   \n",
       "rf_number_of_words             6122.750000   9116.500000  14232.000000   \n",
       "rf_number_of_numbers             27.000000     51.000000     88.000000   \n",
       "rf_number_of_complex_words     1332.000000   1967.500000   3011.250000   \n",
       "rf_average_sen_length            29.689750     31.392476     33.104336   \n",
       "rf_perc_complex_words             0.206099      0.214950      0.223738   \n",
       "rf_fog_index                     20.465911     21.200292     21.911407   \n",
       "rf_number_of_covid_words          0.000000      0.000000     12.000000   \n",
       "rf_number_of_risk_factors        27.000000     37.000000     52.000000   \n",
       "mda_number_of_sentences         201.000000    282.000000    388.000000   \n",
       "mda_number_of_tokens           5911.250000   8367.500000  11545.000000   \n",
       "mda_number_of_words            5498.750000   7783.000000  10705.250000   \n",
       "mda_number_of_numbers           181.000000    280.000000    424.000000   \n",
       "mda_number_of_complex_words    1105.000000   1572.000000   2181.000000   \n",
       "mda_average_sen_length           25.571429     27.432850     29.342129   \n",
       "mda_perc_complex_words            0.193641      0.203478      0.213732   \n",
       "mda_fog_index                    18.331666     19.161522     20.025399   \n",
       "mda_number_of_covid_words         0.000000      0.000000      9.000000   \n",
       "\n",
       "                                        max  \n",
       "full_number_of_sentences       11659.000000  \n",
       "full_number_of_tokens         351271.000000  \n",
       "full_number_of_words          325301.000000  \n",
       "full_number_of_numbers         16641.000000  \n",
       "full_number_of_complex_words   76774.000000  \n",
       "full_average_sen_length           40.606082  \n",
       "full_perc_complex_words            0.299351  \n",
       "full_fog_index                    24.229627  \n",
       "full_number_of_covid_words       590.000000  \n",
       "rf_number_of_sentences          2053.000000  \n",
       "rf_number_of_tokens            61996.000000  \n",
       "rf_number_of_words             60754.000000  \n",
       "rf_number_of_numbers            1737.000000  \n",
       "rf_number_of_complex_words     13401.000000  \n",
       "rf_average_sen_length             51.166667  \n",
       "rf_perc_complex_words              0.304878  \n",
       "rf_fog_index                      30.499240  \n",
       "rf_number_of_covid_words         220.000000  \n",
       "rf_number_of_risk_factors        369.000000  \n",
       "mda_number_of_sentences         7178.000000  \n",
       "mda_number_of_tokens          193365.000000  \n",
       "mda_number_of_words           181664.000000  \n",
       "mda_number_of_numbers           5669.000000  \n",
       "mda_number_of_complex_words    39937.000000  \n",
       "mda_average_sen_length            73.000000  \n",
       "mda_perc_complex_words             0.476190  \n",
       "mda_fog_index                     41.254795  \n",
       "mda_number_of_covid_words        114.000000  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_metric_df[full_metric_df.form == '10-K'].sort_values('full_fog_index').describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>full_number_of_sentences</th>\n",
       "      <td>61026.0</td>\n",
       "      <td>646.564137</td>\n",
       "      <td>351.695860</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>409.000000</td>\n",
       "      <td>555.000000</td>\n",
       "      <td>789.000000</td>\n",
       "      <td>3501.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>full_number_of_tokens</th>\n",
       "      <td>61026.0</td>\n",
       "      <td>20200.684446</td>\n",
       "      <td>11417.590669</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>12488.000000</td>\n",
       "      <td>17140.000000</td>\n",
       "      <td>24506.000000</td>\n",
       "      <td>119607.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>full_number_of_words</th>\n",
       "      <td>61026.0</td>\n",
       "      <td>18861.441877</td>\n",
       "      <td>10908.286108</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>11541.250000</td>\n",
       "      <td>15853.500000</td>\n",
       "      <td>22805.750000</td>\n",
       "      <td>109952.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>full_number_of_numbers</th>\n",
       "      <td>61026.0</td>\n",
       "      <td>723.459755</td>\n",
       "      <td>399.086330</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>479.000000</td>\n",
       "      <td>641.000000</td>\n",
       "      <td>858.000000</td>\n",
       "      <td>6175.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>full_number_of_complex_words</th>\n",
       "      <td>61026.0</td>\n",
       "      <td>3909.694819</td>\n",
       "      <td>2334.625314</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>2353.000000</td>\n",
       "      <td>3261.000000</td>\n",
       "      <td>4707.000000</td>\n",
       "      <td>23210.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>full_average_sen_length</th>\n",
       "      <td>61026.0</td>\n",
       "      <td>28.882377</td>\n",
       "      <td>2.533456</td>\n",
       "      <td>13.500000</td>\n",
       "      <td>27.111195</td>\n",
       "      <td>28.719866</td>\n",
       "      <td>30.520224</td>\n",
       "      <td>45.137931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>full_perc_complex_words</th>\n",
       "      <td>61026.0</td>\n",
       "      <td>0.206291</td>\n",
       "      <td>0.012691</td>\n",
       "      <td>0.140384</td>\n",
       "      <td>0.197877</td>\n",
       "      <td>0.206333</td>\n",
       "      <td>0.214586</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>full_fog_index</th>\n",
       "      <td>61026.0</td>\n",
       "      <td>19.804603</td>\n",
       "      <td>1.133181</td>\n",
       "      <td>15.662289</td>\n",
       "      <td>19.012903</td>\n",
       "      <td>19.757491</td>\n",
       "      <td>20.548404</td>\n",
       "      <td>25.770986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>full_number_of_covid_words</th>\n",
       "      <td>61026.0</td>\n",
       "      <td>13.420837</td>\n",
       "      <td>22.200112</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>318.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rf_number_of_sentences</th>\n",
       "      <td>22263.0</td>\n",
       "      <td>207.651350</td>\n",
       "      <td>278.111279</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>387.000000</td>\n",
       "      <td>1359.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rf_number_of_tokens</th>\n",
       "      <td>22263.0</td>\n",
       "      <td>6942.285900</td>\n",
       "      <td>9389.790841</td>\n",
       "      <td>106.000000</td>\n",
       "      <td>529.000000</td>\n",
       "      <td>1304.000000</td>\n",
       "      <td>12371.000000</td>\n",
       "      <td>48270.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rf_number_of_words</th>\n",
       "      <td>22263.0</td>\n",
       "      <td>6837.940260</td>\n",
       "      <td>9272.329821</td>\n",
       "      <td>98.000000</td>\n",
       "      <td>509.000000</td>\n",
       "      <td>1262.000000</td>\n",
       "      <td>12209.500000</td>\n",
       "      <td>47707.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rf_number_of_numbers</th>\n",
       "      <td>22263.0</td>\n",
       "      <td>48.708889</td>\n",
       "      <td>66.221570</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>71.000000</td>\n",
       "      <td>1103.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rf_number_of_complex_words</th>\n",
       "      <td>22263.0</td>\n",
       "      <td>1443.395230</td>\n",
       "      <td>1978.713976</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>105.000000</td>\n",
       "      <td>261.000000</td>\n",
       "      <td>2544.500000</td>\n",
       "      <td>10167.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rf_average_sen_length</th>\n",
       "      <td>22263.0</td>\n",
       "      <td>33.468518</td>\n",
       "      <td>5.148791</td>\n",
       "      <td>9.291667</td>\n",
       "      <td>30.693889</td>\n",
       "      <td>33.024390</td>\n",
       "      <td>35.500000</td>\n",
       "      <td>82.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rf_perc_complex_words</th>\n",
       "      <td>22263.0</td>\n",
       "      <td>0.206999</td>\n",
       "      <td>0.022670</td>\n",
       "      <td>0.077381</td>\n",
       "      <td>0.195652</td>\n",
       "      <td>0.208687</td>\n",
       "      <td>0.219548</td>\n",
       "      <td>0.364532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rf_fog_index</th>\n",
       "      <td>22263.0</td>\n",
       "      <td>21.667355</td>\n",
       "      <td>2.247122</td>\n",
       "      <td>11.960902</td>\n",
       "      <td>20.441887</td>\n",
       "      <td>21.591899</td>\n",
       "      <td>22.640032</td>\n",
       "      <td>41.395815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rf_number_of_covid_words</th>\n",
       "      <td>22263.0</td>\n",
       "      <td>7.993846</td>\n",
       "      <td>12.365761</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>237.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rf_number_of_risk_factors</th>\n",
       "      <td>22263.0</td>\n",
       "      <td>20.132507</td>\n",
       "      <td>26.523177</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>42.000000</td>\n",
       "      <td>272.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mda_number_of_sentences</th>\n",
       "      <td>53656.0</td>\n",
       "      <td>223.022029</td>\n",
       "      <td>162.624478</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>136.000000</td>\n",
       "      <td>189.000000</td>\n",
       "      <td>264.000000</td>\n",
       "      <td>4151.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mda_number_of_tokens</th>\n",
       "      <td>53656.0</td>\n",
       "      <td>6892.646060</td>\n",
       "      <td>4977.024149</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4183.000000</td>\n",
       "      <td>5865.000000</td>\n",
       "      <td>8239.000000</td>\n",
       "      <td>110404.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mda_number_of_words</th>\n",
       "      <td>53656.0</td>\n",
       "      <td>6345.978213</td>\n",
       "      <td>4609.799117</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3844.000000</td>\n",
       "      <td>5401.000000</td>\n",
       "      <td>7572.000000</td>\n",
       "      <td>102740.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mda_number_of_numbers</th>\n",
       "      <td>53656.0</td>\n",
       "      <td>275.489731</td>\n",
       "      <td>231.288188</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>148.000000</td>\n",
       "      <td>224.000000</td>\n",
       "      <td>338.000000</td>\n",
       "      <td>4422.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mda_number_of_complex_words</th>\n",
       "      <td>53656.0</td>\n",
       "      <td>1245.959818</td>\n",
       "      <td>972.328933</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>734.000000</td>\n",
       "      <td>1041.000000</td>\n",
       "      <td>1482.000000</td>\n",
       "      <td>21243.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mda_average_sen_length</th>\n",
       "      <td>53554.0</td>\n",
       "      <td>28.556346</td>\n",
       "      <td>3.154807</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>26.478539</td>\n",
       "      <td>28.428571</td>\n",
       "      <td>30.414004</td>\n",
       "      <td>144.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mda_perc_complex_words</th>\n",
       "      <td>53554.0</td>\n",
       "      <td>0.194707</td>\n",
       "      <td>0.018425</td>\n",
       "      <td>0.077626</td>\n",
       "      <td>0.183259</td>\n",
       "      <td>0.194831</td>\n",
       "      <td>0.206091</td>\n",
       "      <td>0.357143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mda_fog_index</th>\n",
       "      <td>53554.0</td>\n",
       "      <td>19.210804</td>\n",
       "      <td>1.453872</td>\n",
       "      <td>10.405023</td>\n",
       "      <td>18.261119</td>\n",
       "      <td>19.180790</td>\n",
       "      <td>20.133898</td>\n",
       "      <td>66.488889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mda_number_of_covid_words</th>\n",
       "      <td>53656.0</td>\n",
       "      <td>7.296873</td>\n",
       "      <td>12.830993</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>190.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                count          mean           std         min  \\\n",
       "full_number_of_sentences      61026.0    646.564137    351.695860    2.000000   \n",
       "full_number_of_tokens         61026.0  20200.684446  11417.590669   31.000000   \n",
       "full_number_of_words          61026.0  18861.441877  10908.286108   27.000000   \n",
       "full_number_of_numbers        61026.0    723.459755    399.086330    3.000000   \n",
       "full_number_of_complex_words  61026.0   3909.694819   2334.625314    9.000000   \n",
       "full_average_sen_length       61026.0     28.882377      2.533456   13.500000   \n",
       "full_perc_complex_words       61026.0      0.206291      0.012691    0.140384   \n",
       "full_fog_index                61026.0     19.804603      1.133181   15.662289   \n",
       "full_number_of_covid_words    61026.0     13.420837     22.200112    0.000000   \n",
       "rf_number_of_sentences        22263.0    207.651350    278.111279    6.000000   \n",
       "rf_number_of_tokens           22263.0   6942.285900   9389.790841  106.000000   \n",
       "rf_number_of_words            22263.0   6837.940260   9272.329821   98.000000   \n",
       "rf_number_of_numbers          22263.0     48.708889     66.221570    0.000000   \n",
       "rf_number_of_complex_words    22263.0   1443.395230   1978.713976   11.000000   \n",
       "rf_average_sen_length         22263.0     33.468518      5.148791    9.291667   \n",
       "rf_perc_complex_words         22263.0      0.206999      0.022670    0.077381   \n",
       "rf_fog_index                  22263.0     21.667355      2.247122   11.960902   \n",
       "rf_number_of_covid_words      22263.0      7.993846     12.365761    0.000000   \n",
       "rf_number_of_risk_factors     22263.0     20.132507     26.523177    0.000000   \n",
       "mda_number_of_sentences       53656.0    223.022029    162.624478    0.000000   \n",
       "mda_number_of_tokens          53656.0   6892.646060   4977.024149    0.000000   \n",
       "mda_number_of_words           53656.0   6345.978213   4609.799117    0.000000   \n",
       "mda_number_of_numbers         53656.0    275.489731    231.288188    0.000000   \n",
       "mda_number_of_complex_words   53656.0   1245.959818    972.328933    0.000000   \n",
       "mda_average_sen_length        53554.0     28.556346      3.154807   13.000000   \n",
       "mda_perc_complex_words        53554.0      0.194707      0.018425    0.077626   \n",
       "mda_fog_index                 53554.0     19.210804      1.453872   10.405023   \n",
       "mda_number_of_covid_words     53656.0      7.296873     12.830993    0.000000   \n",
       "\n",
       "                                       25%           50%           75%  \\\n",
       "full_number_of_sentences        409.000000    555.000000    789.000000   \n",
       "full_number_of_tokens         12488.000000  17140.000000  24506.000000   \n",
       "full_number_of_words          11541.250000  15853.500000  22805.750000   \n",
       "full_number_of_numbers          479.000000    641.000000    858.000000   \n",
       "full_number_of_complex_words   2353.000000   3261.000000   4707.000000   \n",
       "full_average_sen_length          27.111195     28.719866     30.520224   \n",
       "full_perc_complex_words           0.197877      0.206333      0.214586   \n",
       "full_fog_index                   19.012903     19.757491     20.548404   \n",
       "full_number_of_covid_words        0.000000      0.000000     22.000000   \n",
       "rf_number_of_sentences           15.000000     37.000000    387.000000   \n",
       "rf_number_of_tokens             529.000000   1304.000000  12371.000000   \n",
       "rf_number_of_words              509.000000   1262.000000  12209.500000   \n",
       "rf_number_of_numbers              8.000000     19.000000     71.000000   \n",
       "rf_number_of_complex_words      105.000000    261.000000   2544.500000   \n",
       "rf_average_sen_length            30.693889     33.024390     35.500000   \n",
       "rf_perc_complex_words             0.195652      0.208687      0.219548   \n",
       "rf_fog_index                     20.441887     21.591899     22.640032   \n",
       "rf_number_of_covid_words          0.000000      0.000000     12.000000   \n",
       "rf_number_of_risk_factors         1.000000      3.000000     42.000000   \n",
       "mda_number_of_sentences         136.000000    189.000000    264.000000   \n",
       "mda_number_of_tokens           4183.000000   5865.000000   8239.000000   \n",
       "mda_number_of_words            3844.000000   5401.000000   7572.000000   \n",
       "mda_number_of_numbers           148.000000    224.000000    338.000000   \n",
       "mda_number_of_complex_words     734.000000   1041.000000   1482.000000   \n",
       "mda_average_sen_length           26.478539     28.428571     30.414004   \n",
       "mda_perc_complex_words            0.183259      0.194831      0.206091   \n",
       "mda_fog_index                    18.261119     19.180790     20.133898   \n",
       "mda_number_of_covid_words         0.000000      0.000000     11.000000   \n",
       "\n",
       "                                        max  \n",
       "full_number_of_sentences        3501.000000  \n",
       "full_number_of_tokens         119607.000000  \n",
       "full_number_of_words          109952.000000  \n",
       "full_number_of_numbers          6175.000000  \n",
       "full_number_of_complex_words   23210.000000  \n",
       "full_average_sen_length           45.137931  \n",
       "full_perc_complex_words            0.333333  \n",
       "full_fog_index                    25.770986  \n",
       "full_number_of_covid_words       318.000000  \n",
       "rf_number_of_sentences          1359.000000  \n",
       "rf_number_of_tokens            48270.000000  \n",
       "rf_number_of_words             47707.000000  \n",
       "rf_number_of_numbers            1103.000000  \n",
       "rf_number_of_complex_words     10167.000000  \n",
       "rf_average_sen_length             82.200000  \n",
       "rf_perc_complex_words              0.364532  \n",
       "rf_fog_index                      41.395815  \n",
       "rf_number_of_covid_words         237.000000  \n",
       "rf_number_of_risk_factors        272.000000  \n",
       "mda_number_of_sentences         4151.000000  \n",
       "mda_number_of_tokens          110404.000000  \n",
       "mda_number_of_words           102740.000000  \n",
       "mda_number_of_numbers           4422.000000  \n",
       "mda_number_of_complex_words    21243.000000  \n",
       "mda_average_sen_length           144.000000  \n",
       "mda_perc_complex_words             0.357143  \n",
       "mda_fog_index                     66.488889  \n",
       "mda_number_of_covid_words        190.000000  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_metric_df[full_metric_df.form == '10-Q'].sort_values('full_fog_index').describe().T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final clean for merge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert link to fname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_metric_df['fname'] = full_metric_df['link'].apply(lambda x: functions.extract_data_edgar_link(x)['fname'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drop columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_metric_df = full_metric_df.drop(['link','filingDate', 'reportDate'], axis=1, errors = 'ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Store"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_metric_df.to_stata(pipeline / 'out'/ 'text_statistics.dta', write_index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_metric_df.to_excel(pipeline / 'out'/ 'text_statistics.xlsx', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "138px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": false,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
